import streamlit as st
import pandas as pd
import io
import time

def load_csv(uploaded_file: io.BytesIO) -> pd.DataFrame:
    try:
        df = pd.read_csv(uploaded_file, dtype=str, encoding="utf-8", sep=",", engine="c")
    except UnicodeDecodeError:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, dtype=str, encoding="shift_jis", sep=",", engine="c")
    df.columns = df.columns.str.strip().str.replace("ã€€", "", regex=False)
    rename_map = {}
    for col in df.columns:
        if "æ—¥ä»˜" in col or col.lower() in ["date", "day"]:
            rename_map[col] = "æ—¥ä»˜"
        if "æ™‚åˆ»" in col or col.lower() in ["time"]:
            rename_map[col] = "æ™‚åˆ»"
    df.rename(columns=rename_map, inplace=True)
    if "æ—¥ä»˜" not in df.columns or "æ™‚åˆ»" not in df.columns:
        return pd.DataFrame()
    dt_str = df["æ—¥ä»˜"].astype(str).str.strip() + " " + df["æ™‚åˆ»"].astype(str).str.strip()
    df["datetime"] = pd.to_datetime(dt_str, errors="coerce")
    df.dropna(subset=["datetime"], inplace=True)
    return df.reset_index(drop=True)

def merge_and_sort(dataframes: list[pd.DataFrame]) -> pd.DataFrame:
    return (
        pd.concat(dataframes, ignore_index=True)
          .drop_duplicates()
          .sort_values("datetime")
          .reset_index(drop=True)
    )

def filter_by_interval(df: pd.DataFrame, interval_seconds: int, base_time=None) -> pd.DataFrame:
    if interval_seconds <= 0:
        return df.reset_index(drop=True)
    if base_time is None:
        base_time = df["datetime"].min()
    df_filtered = (
        df.groupby(((df["datetime"] - base_time).dt.total_seconds() // interval_seconds).astype(int))
          .first()
          .reset_index(drop=True)
    )
    return df_filtered

def generate_csv(df: pd.DataFrame) -> bytes:
    if "datetime" in df.columns:
        df = df.drop(columns=["datetime"])
    buf = io.StringIO()
    df.to_csv(buf, index=False, encoding="utf-8-sig")
    return buf.getvalue().encode("utf-8-sig")

def select_interval() -> int:
    interval_option = st.selectbox(
        "æŠ½å‡ºé–“éš”ã‚’é¸æŠ",
        options=[
            ("å…¨ä»¶æŠ½å‡º(0)", 0),
            ("5ç§’", 5),
            ("10ç§’", 10),
            ("30ç§’", 30),
            ("1åˆ†", 60),
            ("5åˆ†", 300),
            ("10åˆ†", 600)
        ],
        index=4,
        format_func=lambda x: x[0]
    )
    return interval_option[1]

def main():
    st.set_page_config(page_title="ãƒ­ã‚°æ•´å½¢ á”¦âŠâŠá”¨", layout="centered", initial_sidebar_state="expanded")
    st.title("ãƒ­ã‚°æ•´å½¢ á”¦ê™¬á”¨")

    interval_seconds = select_interval()
    uploaded_files = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["csv"], accept_multiple_files=True)
    start_clicked = st.button("â–¶ ã‚¹ã‚¿ãƒ¼ãƒˆ")

    if start_clicked:
        overall_start = time.time()
        if not uploaded_files:
            st.warning("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
            st.stop()

        progress = st.progress(0, text="èª­ã¿è¾¼ã¿ä¸­â€¦")
        temp_dfs = []

        # ã¾ãšã™ã¹ã¦èª­ã¿è¾¼ã‚“ã§æœ€å°æ—¥æ™‚ã‚’å–å¾—
        read_start = time.time()
        for idx, file in enumerate(uploaded_files, start=1):
            progress.progress(int(idx / len(uploaded_files) * 30),
                              text=f"[{idx}/{len(uploaded_files)}] {file.name} èª­ã¿è¾¼ã¿ä¸­â€¦")
            df = load_csv(file)
            if df.empty:
                st.error(f"{file.name} ã«ã€æ—¥ä»˜ã€ã€æ™‚åˆ»ã€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            else:
                temp_dfs.append(df)
        if not temp_dfs:
            st.stop()

        overall_base_time = min(df["datetime"].min() for df in temp_dfs)
        read_time = time.time() - read_start

        # èª­ã¿è¾¼ã¿â†’å³é–“å¼•ã
        progress.progress(50, text="é–“å¼•ãä¸­â€¦")
        filter_start = time.time()
        reduced_dfs = [filter_by_interval(df, interval_seconds, base_time=overall_base_time) for df in temp_dfs]
        filter_time = time.time() - filter_start

        # é–“å¼•ãå¾Œãƒ‡ãƒ¼ã‚¿ã‚’çµåˆï¼‹ã‚½ãƒ¼ãƒˆ
        progress.progress(80, text="çµåˆä¸­â€¦")
        merge_start = time.time()
        merged_df = merge_and_sort(reduced_dfs)
        merge_time = time.time() - merge_start

        st.info(f"çµåˆå¾Œã®ä»¶æ•°: {len(merged_df)} ä»¶")
        if merged_df.empty:
            st.warning("æŠ½å‡ºçµæœãŒã‚ã‚Šã¾ã›ã‚“")
            st.stop()

        csv_bytes = generate_csv(merged_df)
        progress.progress(100, text="å®Œäº†ï¼")

        overall_time = time.time() - overall_start
        st.success(
            f"å®Œäº†ï¼ åˆè¨ˆ {len(merged_df)} ä»¶ã‚’æŠ½å‡ºã—ã¾ã—ãŸ\n"
            f"å…¨ä½“: {overall_time:.2f}ç§’ | èª­ã¿è¾¼ã¿: {read_time:.2f}ç§’ | é–“å¼•ã: {filter_time:.2f}ç§’ | çµåˆ: {merge_time:.2f}ç§’"
        )

        st.download_button(
            "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯ã“ã¡ã‚‰ğŸ¦€",
            csv_bytes,
            file_name="filtered_interval_data.csv",
            mime="text/csv"
        )

if __name__ == "__main__":
    main()
