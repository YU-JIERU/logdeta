import streamlit as st
import pandas as pd
import io
import time

# å¹´2æ¡â†’4æ¡å¤‰æ›
def convert_short_year_to_full(date_str: str) -> str:
    parts = date_str.split("/")
    if len(parts) == 3 and len(parts[0]) == 2:
        year = int(parts[0])
        year += 2000 if year < 70 else 1900
        return f"{year}/{parts[1]}/{parts[2]}"
    return date_str

# CSVèª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†
def load_csv(uploaded_file: io.BytesIO) -> pd.DataFrame:
    try:
        df = pd.read_csv(uploaded_file, dtype=str, encoding='utf-8', engine='pyarrow')
    except Exception:
        uploaded_file.seek(0)
        try:
            df = pd.read_csv(uploaded_file, dtype=str, encoding='shift_jis', engine='c')
        except Exception as e:
            st.warning(f"{uploaded_file.name} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return pd.DataFrame()

    df.columns = df.columns.str.strip().str.replace(r"\s+", "", regex=True).str.replace('ã€€', '')
    rename_map = {
        col: 'æ—¥ä»˜' if 'æ—¥ä»˜' in col or col.lower() in ['date', 'day']
        else 'æ™‚åˆ»' if 'æ™‚åˆ»' in col or col.lower() == 'time'
        else col for col in df.columns
    }
    df.rename(columns=rename_map, inplace=True)

    if 'æ—¥ä»˜' not in df.columns or 'æ™‚åˆ»' not in df.columns:
        st.warning(f"{uploaded_file.name} ã« 'æ—¥ä»˜' ã¾ãŸã¯ 'æ™‚åˆ»' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return pd.DataFrame()

    # 2é‡ãƒ˜ãƒƒãƒ€ãƒ¼å¯¾å¿œ + ã€Œè³‡æ–™ã€ãªã©ã®ãƒ©ãƒ™ãƒ«è¡Œã‚’é™¤å¤–
    df = df[~df['æ—¥ä»˜'].str.contains('æ—¥ä»˜', na=False) & ~df['æ™‚åˆ»'].str.contains('æ™‚åˆ»', na=False)]
    df = df[~df['æ—¥ä»˜'].str.contains('è³‡æ–™', na=False)]  # â† è¿½åŠ ï¼šè³‡æ–™è¡Œã‚’é™¤å¤–

    df['æ—¥ä»˜'] = df['æ—¥ä»˜'].astype(str).str.replace(r'[\sã€€\t\r\n]+', '', regex=True)
    df['æ™‚åˆ»'] = df['æ™‚åˆ»'].astype(str).str.replace(r'[\sã€€\t\r\n]+', '', regex=True)
    df = df[(df['æ—¥ä»˜'] != '') & (df['æ™‚åˆ»'] != '')]
    if df.empty:
        st.warning(f"{uploaded_file.name} ã«æœ‰åŠ¹ãªè¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return pd.DataFrame()

    df['æ—¥ä»˜'] = df['æ—¥ä»˜'].apply(convert_short_year_to_full)

    try:
        df['æ—¥ä»˜'] = pd.to_datetime(df['æ—¥ä»˜'], format='%Y/%m/%d').dt.strftime('%Y-%m-%d')
    except Exception as e:
        st.warning(f"{uploaded_file.name} ã®æ—¥ä»˜å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()

    try:
        df['æ™‚åˆ»'] = pd.to_datetime(df['æ™‚åˆ»'], errors='coerce').dt.strftime('%H:%M:%S')
    except Exception as e:
        st.warning(f"{uploaded_file.name} ã®æ™‚åˆ»å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()

    dt_str = df['æ—¥ä»˜'] + ' ' + df['æ™‚åˆ»']
    df['datetime'] = pd.to_datetime(dt_str, errors='coerce')
    df.dropna(subset=['datetime'], inplace=True)
    return df.reset_index(drop=True)

# é–“å¼•ãå‡¦ç†
def filter_by_interval(df: pd.DataFrame, interval_seconds: int) -> pd.DataFrame:
    if 'datetime' not in df.columns:
        st.error("datetimeåˆ—ã‚‚ã—ãã¯æ—¥ä»˜ãƒ»æ™‚åˆ»åˆ—ãŒã‚ã‚Šã¾ã›ã‚“")
        st.stop()

    if interval_seconds <= 0:
        return df.reset_index(drop=True)

    df['datetime_rounded'] = df['datetime'].dt.floor(f'{interval_seconds}S')
    reduced = df.groupby('datetime_rounded').first().copy()
    reduced.rename(columns={'datetime_rounded': 'datetime'}, inplace=True)
    reduced.reset_index(inplace=True)

    important_cols = [col for col in ['å¾ªç’°æ°´æµé‡'] if col in reduced.columns]
    if important_cols:
        reduced = reduced.dropna(subset=important_cols)

    return reduced.reset_index(drop=True)

# ãƒãƒ¼ã‚¸ï¼†ä¸¦ã³æ›¿ãˆ
def merge_and_sort(dataframes: list[pd.DataFrame]) -> pd.DataFrame:
    non_empty = [df for df in dataframes if not df.empty]
    if not non_empty:
        return pd.DataFrame()

    merged = pd.concat(non_empty, ignore_index=True).drop_duplicates().sort_values('datetime').reset_index(drop=True)

    if 'datetime' in merged.columns and 'æ™‚åˆ»' in merged.columns:
        cols = list(merged.columns)
        cols.remove('datetime')
        time_idx = cols.index('æ™‚åˆ»') + 1
        cols.insert(time_idx, 'datetime')
        merged = merged[cols]

    return merged

# CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ç”Ÿæˆ
def generate_csv(df: pd.DataFrame) -> bytes:
    buf = io.StringIO()
    df.to_csv(buf, index=False, encoding='utf-8-sig')
    return buf.getvalue().encode('utf-8-sig')

# æŠ½å‡ºé–“éš”ã‚»ãƒ¬ã‚¯ã‚¿
def select_interval() -> int:
    options = ['å…¨ä»¶æŠ½å‡º(0)', '5ç§’', '10ç§’', '30ç§’', '1åˆ†', '5åˆ†', '10åˆ†']
    seconds_map = {
        'å…¨ä»¶æŠ½å‡º(0)': 0,
        '5ç§’': 5,
        '10ç§’': 10,
        '30ç§’': 30,
        '1åˆ†': 60,
        '5åˆ†': 300,
        '10åˆ†': 600
    }
    option = st.selectbox('æŠ½å‡ºé–“éš”ã‚’é¸æŠ', options, index=4)
    return seconds_map[option]

# ã‚¢ãƒ—ãƒªæœ¬ä½“
def main():
    st.set_page_config(page_title='ãƒ­ã‚°æ•´å½¢ á”¦--á”¨', layout='centered', initial_sidebar_state='expanded')
    st.title('ãƒ­ã‚°æ•´å½¢ á”¦ê™¬á”¨')

    interval_seconds = select_interval()
    uploaded_files = st.file_uploader('CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„', type=['csv'], accept_multiple_files=True)
    start_clicked = st.button('â–¶ ã‚¹ã‚¿ãƒ¼ãƒˆ')

    if start_clicked:
        if not uploaded_files:
            st.warning('CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„')
            st.stop()

        progress = st.progress(0)
        status_text = st.empty()

        temp_dfs = []
        start_time = time.time()
        total_files = len(uploaded_files)

        # èª­ã¿è¾¼ã¿å‡¦ç†
        for idx, file in enumerate(uploaded_files):
            df = load_csv(file)
            temp_dfs.append(df)

            progress_percent = int((idx + 1) / total_files * 30)
            progress.progress(progress_percent)

            status_text.text(
                f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­: {idx + 1}/{total_files} - {file.name} ({len(df)} è¡Œ)"
            )

        read_time = time.time() - start_time

        if not any(not df.empty for df in temp_dfs):
            st.warning('æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“')
            st.stop()

        # é–“å¼•ãå‡¦ç†
        start_time = time.time()
        reduced_dfs = []
        for idx, df in enumerate(temp_dfs):
            reduced_df = filter_by_interval(df, interval_seconds)
            reduced_dfs.append(reduced_df)

            progress_percent = 30 + int((idx + 1) / len(temp_dfs) * 40)
            progress.progress(progress_percent)

            status_text.text(
                f"ğŸ”§ é–“å¼•ãå‡¦ç†ä¸­: {idx + 1}/{len(temp_dfs)} ãƒ•ã‚¡ã‚¤ãƒ«ç›®"
            )

        filter_time = time.time() - start_time

        # çµåˆå‡¦ç†
        start_time = time.time()
        merged_df = merge_and_sort(reduced_dfs)
        merge_time = time.time() - start_time

        progress.progress(100)
        status_text.text('âœ… å®Œäº†ï¼')

        st.success(
            f"å‡¦ç†å®Œäº†ï¼ åˆè¨ˆ {len(merged_df)} ä»¶ã‚’æŠ½å‡ºã—ã¾ã—ãŸ\n"
            f"èª­ã¿è¾¼ã¿æ™‚é–“: {read_time:.2f}ç§’ | é–“å¼•ãæ™‚é–“: {filter_time:.2f}ç§’ | çµåˆæ™‚é–“: {merge_time:.2f}ç§’"
        )

        csv_bytes = generate_csv(merged_df)
        st.download_button('ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯ã“ã¡ã‚‰', csv_bytes, file_name='filtered_interval_data.csv', mime='text/csv')

# ã‚¢ãƒ—ãƒªå®Ÿè¡Œ
if __name__ == '__main__':
    main()
